{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import warnings\n",
    "import glob as gb\n",
    "import os\n",
    "from importlib import reload\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from models.alexNet import MY_AlexNet\n",
    "from models.vgg16 import MY_VGG16\n",
    "from utils.utils import *\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração dos Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data_C10 = datasets.CIFAR10(\n",
    "    root=\"../data/datasets/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data_C10 = datasets.CIFAR10(\n",
    "    root=\"../data/datasets/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ../data/datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../data/datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_C10, test_data_C10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building-vs-forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"../data/datasets/buildings-vs-forests/test_set.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/datasets/buildings-vs-forests/\")\n",
    "    \n",
    "with ZipFile(\"../data/datasets/buildings-vs-forests/traning_set.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/datasets/buildings-vs-forests/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0, 'forest': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian_path = '../data/datasets/buildings-vs-forests/traning_set'\n",
    "test_path = '../data/datasets/buildings-vs-forests/test_set'\n",
    "\n",
    "training_data_BF = ImageFolder(trian_path, transform = tfm)\n",
    "test_data_BF = ImageFolder(test_path, transform = tfm)\n",
    "\n",
    "len_train = len(training_data_BF)\n",
    "len_test = len(test_data_BF)\n",
    "\n",
    "training_data_BF.class_to_idx\n",
    "test_data_BF.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação - CIFAR10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Epócas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [22:02<00:00, 330.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Epochs</th>\n",
       "      <th>10 Epochs</th>\n",
       "      <th>20 Epochs</th>\n",
       "      <th>50 Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5 Epochs  10 Epochs  20 Epochs  50 Epochs\n",
       "0       1.0        0.0      0.132      0.140\n",
       "1       0.0        1.0      0.000      0.304\n",
       "2       0.0        0.0      0.000      0.169\n",
       "3       0.0        0.0      0.000      0.000\n",
       "4       0.0        0.0      0.293      0.002\n",
       "5       0.0        0.0      0.104      0.001\n",
       "6       0.0        0.0      0.000      0.000\n",
       "7       0.0        0.0      0.000      0.000\n",
       "8       0.0        0.0      0.000      0.220\n",
       "9       0.0        0.0      0.934      0.783"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'5 Epochs': accuracys[0], '10 Epochs': accuracys[1], '20 Epochs': accuracys[2], '50 Epochs': accuracys[3]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:12<00:00, 624.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size: 64</th>\n",
       "      <th>Batch Size: 128</th>\n",
       "      <th>Batch Size: 256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.562</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size: 64  Batch Size: 128  Batch Size: 256\n",
       "0           0.796            0.000            0.000\n",
       "1           0.000            0.000            0.000\n",
       "2           0.002            0.000            0.000\n",
       "3           0.000            0.000            0.000\n",
       "4           0.039            0.009            0.000\n",
       "5           0.000            0.000            0.002\n",
       "6           0.000            0.000            0.000\n",
       "7           0.000            0.000            0.000\n",
       "8           0.005            0.562            1.000\n",
       "9           0.529            0.731            0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "        \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size: 64': accuracys[0], 'Batch Size: 128': accuracys[1], 'Batch Size: 256': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [38:12<00:00, 764.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate: 1e-2</th>\n",
       "      <th>Learning Rate: 1e-3</th>\n",
       "      <th>Learning Rate: 1e-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.549</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate: 1e-2  Learning Rate: 1e-3  Learning Rate: 1e-4\n",
       "0                0.706                0.978                0.009\n",
       "1                0.785                0.000                0.000\n",
       "2                0.559                0.016                0.000\n",
       "3                0.622                0.000                0.000\n",
       "4                0.549                0.000                0.000\n",
       "5                0.577                0.000                0.000\n",
       "6                0.767                0.400                0.999\n",
       "7                0.684                0.000                0.000\n",
       "8                0.840                0.002                0.000\n",
       "9                0.732                0.000                0.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=64)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate: 1e-2': accuracys[0], 'Learning Rate: 1e-3': accuracys[1], 'Learning Rate: 1e-4': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [39:48<00:00, 796.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter 1</th>\n",
       "      <th>Iter 2</th>\n",
       "      <th>Iter 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.589</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.406</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.701</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.747</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iter 1  Iter 2  Iter 3\n",
       "0   0.679   0.724   0.679\n",
       "1   0.761   0.803   0.799\n",
       "2   0.589   0.367   0.523\n",
       "3   0.406   0.331   0.627\n",
       "4   0.756   0.750   0.614\n",
       "5   0.565   0.548   0.450\n",
       "6   0.701   0.748   0.739\n",
       "7   0.742   0.815   0.687\n",
       "8   0.747   0.690   0.848\n",
       "9   0.767   0.714   0.800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Iter 1': accuracys[0], 'Iter 2': accuracys[1], 'Iter 3': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:05:47<00:00, 986.94s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Epochs</th>\n",
       "      <th>10 Epochs</th>\n",
       "      <th>20 Epochs</th>\n",
       "      <th>50 Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5 Epochs  10 Epochs  20 Epochs  50 Epochs\n",
       "0       0.0        0.0        0.0        0.0\n",
       "1       1.0        1.0        0.0        1.0\n",
       "2       0.0        0.0        1.0        0.0\n",
       "3       0.0        0.0        0.0        0.0\n",
       "4       0.0        0.0        0.0        0.0\n",
       "5       0.0        0.0        0.0        0.0\n",
       "6       0.0        0.0        0.0        0.0\n",
       "7       0.0        0.0        0.0        0.0\n",
       "8       0.0        0.0        0.0        0.0\n",
       "9       0.0        0.0        0.0        0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = []\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'5 Epochs': accuracys[0], '10 Epochs': accuracys[1], '20 Epochs': accuracys[2], '50 Epochs': accuracys[3]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:38:57<00:00, 1979.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size: 64</th>\n",
       "      <th>Batch Size: 128</th>\n",
       "      <th>Batch Size: 256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size: 64  Batch Size: 128  Batch Size: 256\n",
       "0             0.0              0.0              0.0\n",
       "1             1.0              0.0              0.0\n",
       "2             0.0              0.0              1.0\n",
       "3             0.0              0.0              0.0\n",
       "4             0.0              1.0              0.0\n",
       "5             0.0              0.0              0.0\n",
       "6             0.0              0.0              0.0\n",
       "7             0.0              0.0              0.0\n",
       "8             0.0              0.0              0.0\n",
       "9             0.0              0.0              0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "        \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size: 64': accuracys[0], 'Batch Size: 128': accuracys[1], 'Batch Size: 256': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:57:06<00:00, 2342.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate: 1e-2</th>\n",
       "      <th>Learning Rate: 1e-3</th>\n",
       "      <th>Learning Rate: 1e-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate: 1e-2  Learning Rate: 1e-3  Learning Rate: 1e-4\n",
       "0                  0.0                  0.0                  0.0\n",
       "1                  0.0                  1.0                  0.0\n",
       "2                  0.0                  0.0                  0.0\n",
       "3                  0.0                  0.0                  0.0\n",
       "4                  0.0                  0.0                  0.0\n",
       "5                  1.0                  0.0                  0.0\n",
       "6                  0.0                  0.0                  1.0\n",
       "7                  0.0                  0.0                  0.0\n",
       "8                  0.0                  0.0                  0.0\n",
       "9                  0.0                  0.0                  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=64)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate: 1e-2': accuracys[0], 'Learning Rate: 1e-3': accuracys[1], 'Learning Rate: 1e-4': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:56:35<00:00, 2331.79s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter 1</th>\n",
       "      <th>Iter 2</th>\n",
       "      <th>Iter 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iter 1  Iter 2  Iter 3\n",
       "0     0.0     0.0     0.0\n",
       "1     0.0     0.0     0.0\n",
       "2     0.0     0.0     0.0\n",
       "3     0.0     0.0     0.0\n",
       "4     0.0     0.0     0.0\n",
       "5     1.0     1.0     1.0\n",
       "6     0.0     0.0     0.0\n",
       "7     0.0     0.0     0.0\n",
       "8     0.0     0.0     0.0\n",
       "9     0.0     0.0     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Iter 1': accuracys[0], 'Iter 2': accuracys[1], 'Iter 3': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação - Building-vs-Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:30<00:00, 97.74s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.692501</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.691036</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.691055</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>52.469813</td>\n",
       "      <td>0.685558</td>\n",
       "      <td>0.524698</td>\n",
       "      <td>0.524698</td>\n",
       "      <td>0.524698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0       5  52.030735  0.692501  0.520307      0.520307   0.520307\n",
       "1      10  52.030735  0.691036  0.520307      0.520307   0.520307\n",
       "2      20  52.030735  0.691055  0.520307      0.520307   0.520307\n",
       "3      50  52.469813  0.685558  0.524698      0.524698   0.524698"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 2)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Epochs': epochs, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:08<00:00, 222.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.152476</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.883087</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.775018</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0          64  52.030735  1.152476  0.520307      0.520307   0.520307\n",
       "1         128  52.030735  0.883087  0.520307      0.520307   0.520307\n",
       "2         256  52.030735  0.775018  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))  \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size': batch_sizes, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [14:21<00:00, 287.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.422985</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.188879</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>2.072739</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0         0.0100  52.030735  1.422985  0.520307      0.520307   0.520307\n",
       "1         0.0010  52.030735  1.188879  0.520307      0.520307   0.520307\n",
       "2         0.0001  52.030735  2.072739  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=64)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate': learnings, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:12<00:00, 224.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.799122</td>\n",
       "      <td>1.576599</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.527991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.994512</td>\n",
       "      <td>1.443155</td>\n",
       "      <td>0.549945</td>\n",
       "      <td>0.549945</td>\n",
       "      <td>0.549945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53.896817</td>\n",
       "      <td>1.510527</td>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.538968</td>\n",
       "      <td>0.538968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0  52.799122  1.576599  0.527991      0.527991   0.527991\n",
       "1  54.994512  1.443155  0.549945      0.549945   0.549945\n",
       "2  53.896817  1.510527  0.538968      0.538968   0.538968"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:54<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projetos\\Python\\UFJF\\8 Periodo\\Trabalho_vc_NEO\\src\\main.ipynb Cell 46\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projetos/Python/UFJF/8%20Periodo/Trabalho_vc_NEO/src/main.ipynb#X63sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projetos/Python/UFJF/8%20Periodo/Trabalho_vc_NEO/src/main.ipynb#X63sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projetos/Python/UFJF/8%20Periodo/Trabalho_vc_NEO/src/main.ipynb#X63sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     train(train_dataloader, model, loss_fn, optimizer, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projetos/Python/UFJF/8%20Periodo/Trabalho_vc_NEO/src/main.ipynb#X63sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     predicts, labels, accuracy, error \u001b[39m=\u001b[39m test_new_metrics(test_dataloader, model, loss_fn, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projetos/Python/UFJF/8%20Periodo/Trabalho_vc_NEO/src/main.ipynb#X63sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m predicts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(predicts)\u001b[39m.\u001b[39mravel()\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Projetos\\Python\\UFJF\\8 Periodo\\Trabalho_vc_NEO\\src\\utils\\utils.py:22\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m# Itera sobre os lotes\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m batch, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[0;32m     21\u001b[0m     \u001b[39m# transforma as entradas no formato do dispositivo utilizado (CPU ou GPU)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     24\u001b[0m     \u001b[39m# Faz a predição para os valores atuais dos parâmetros\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     pred \u001b[39m=\u001b[39m model(X)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 2)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Epochs': epochs, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size': batch_sizes, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=64)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate': learnings, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
