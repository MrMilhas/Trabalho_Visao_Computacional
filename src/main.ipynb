{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho de Visão Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das Bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import warnings\n",
    "import glob as gb\n",
    "import os\n",
    "from importlib import reload\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from models.alexNet import MY_AlexNet\n",
    "from models.vgg16 import MY_VGG16\n",
    "from utils.utils import *\n",
    "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração dos Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CIFAR-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "training_data_C10 = datasets.CIFAR10(\n",
    "    root=\"../data/datasets/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data_C10 = datasets.CIFAR10(\n",
    "    root=\"../data/datasets/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset CIFAR10\n",
       "     Number of datapoints: 50000\n",
       "     Root location: ../data/datasets/\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset CIFAR10\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../data/datasets/\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_C10, test_data_C10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Building-vs-forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"../data/datasets/buildings-vs-forests/test_set.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/datasets/buildings-vs-forests/\")\n",
    "    \n",
    "with ZipFile(\"../data/datasets/buildings-vs-forests/traning_set.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"../data/datasets/buildings-vs-forests/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5],[0.5, 0.5, 0.5])   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0, 'forest': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trian_path = '../data/datasets/buildings-vs-forests/traning_set'\n",
    "test_path = '../data/datasets/buildings-vs-forests/test_set'\n",
    "\n",
    "training_data_BF = ImageFolder(trian_path, transform = tfm)\n",
    "test_data_BF = ImageFolder(test_path, transform = tfm)\n",
    "\n",
    "len_train = len(training_data_BF)\n",
    "len_test = len(test_data_BF)\n",
    "\n",
    "training_data_BF.class_to_idx\n",
    "test_data_BF.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação - CIFAR10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Epócas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [22:02<00:00, 330.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Epochs</th>\n",
       "      <th>10 Epochs</th>\n",
       "      <th>20 Epochs</th>\n",
       "      <th>50 Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5 Epochs  10 Epochs  20 Epochs  50 Epochs\n",
       "0       1.0        0.0      0.132      0.140\n",
       "1       0.0        1.0      0.000      0.304\n",
       "2       0.0        0.0      0.000      0.169\n",
       "3       0.0        0.0      0.000      0.000\n",
       "4       0.0        0.0      0.293      0.002\n",
       "5       0.0        0.0      0.104      0.001\n",
       "6       0.0        0.0      0.000      0.000\n",
       "7       0.0        0.0      0.000      0.000\n",
       "8       0.0        0.0      0.000      0.220\n",
       "9       0.0        0.0      0.934      0.783"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'5 Epochs': accuracys[0], '10 Epochs': accuracys[1], '20 Epochs': accuracys[2], '50 Epochs': accuracys[3]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [31:12<00:00, 624.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size: 64</th>\n",
       "      <th>Batch Size: 128</th>\n",
       "      <th>Batch Size: 256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.796</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005</td>\n",
       "      <td>0.562</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size: 64  Batch Size: 128  Batch Size: 256\n",
       "0           0.796            0.000            0.000\n",
       "1           0.000            0.000            0.000\n",
       "2           0.002            0.000            0.000\n",
       "3           0.000            0.000            0.000\n",
       "4           0.039            0.009            0.000\n",
       "5           0.000            0.000            0.002\n",
       "6           0.000            0.000            0.000\n",
       "7           0.000            0.000            0.000\n",
       "8           0.005            0.562            1.000\n",
       "9           0.529            0.731            0.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "        \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size: 64': accuracys[0], 'Batch Size: 128': accuracys[1], 'Batch Size: 256': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [38:12<00:00, 764.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate: 1e-2</th>\n",
       "      <th>Learning Rate: 1e-3</th>\n",
       "      <th>Learning Rate: 1e-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.559</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.549</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.577</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.684</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate: 1e-2  Learning Rate: 1e-3  Learning Rate: 1e-4\n",
       "0                0.706                0.978                0.009\n",
       "1                0.785                0.000                0.000\n",
       "2                0.559                0.016                0.000\n",
       "3                0.622                0.000                0.000\n",
       "4                0.549                0.000                0.000\n",
       "5                0.577                0.000                0.000\n",
       "6                0.767                0.400                0.999\n",
       "7                0.684                0.000                0.000\n",
       "8                0.840                0.002                0.000\n",
       "9                0.732                0.000                0.000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=64)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate: 1e-2': accuracys[0], 'Learning Rate: 1e-3': accuracys[1], 'Learning Rate: 1e-4': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [37:55<00:00, 758.51s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m     accuracys\u001b[38;5;241m.\u001b[39mappend(accuracy)\n\u001b[0;32m     43\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(test_error)\n\u001b[1;32m---> 45\u001b[0m df_loss \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrain_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m df_loss\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/results/cifar10_alexNet_loss.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     48\u001b[0m df_cm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred_1\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_list[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_1\u001b[39m\u001b[38;5;124m'\u001b[39m:label_list[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred_2\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_list[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_2\u001b[39m\u001b[38;5;124m'\u001b[39m:label_list[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPred_3\u001b[39m\u001b[38;5;124m'\u001b[39m: pred_list[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel_3\u001b[39m\u001b[38;5;124m'\u001b[39m:label_list[\u001b[38;5;241m2\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\construction.py:631\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    628\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    633\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:126\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    123\u001b[0m arr: ArrayLike\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mrange\u001b[39m)):\n\u001b[1;32m--> 126\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_1d_object_array_from_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# The caller is responsible for ensuring that we have np.ndarray\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m#  or ExtensionArray here.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     arr \u001b[38;5;241m=\u001b[39m values\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1565\u001b[0m, in \u001b[0;36mconstruct_1d_object_array_from_listlike\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;66;03m# numpy will try to interpret nested lists as further dimensions, hence\u001b[39;00m\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;66;03m# making a 1D array that contains list-likes is a bit tricky:\u001b[39;00m\n\u001b[0;32m   1564\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(values), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1565\u001b[0m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:1032\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train_error = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, test_error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "        train_loss.append(train_error)\n",
    "        test_loss.append(test_error)\n",
    "\n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    pred_list.append(predicts)\n",
    "    label_list.append(labels)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(test_error)\n",
    "\n",
    "aux_list = []\n",
    "for i in train_loss:\n",
    "    aux_list.append(i.item())\n",
    "\n",
    "df_loss = pd.DataFrame({'Train_loss': aux_list, 'Test_loss': test_loss})\n",
    "df_loss.to_csv('../data/results/cifar10_alexNet_loss.csv', index = False)\n",
    "\n",
    "df_cm = pd.DataFrame({'Pred_1': pred_list[0], 'Label_1':label_list[0], 'Pred_2': pred_list[1], 'Label_2':label_list[1], 'Pred_3': pred_list[2], 'Label_3':label_list[2]})\n",
    "df_cm.to_csv('../data/results/cifar10_alexNet_confusion_matrix.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({'Iter 1': accuracys[0], 'Iter 2': accuracys[1], 'Iter 3': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_alexNet_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:05:47<00:00, 986.94s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5 Epochs</th>\n",
       "      <th>10 Epochs</th>\n",
       "      <th>20 Epochs</th>\n",
       "      <th>50 Epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   5 Epochs  10 Epochs  20 Epochs  50 Epochs\n",
       "0       0.0        0.0        0.0        0.0\n",
       "1       1.0        1.0        0.0        1.0\n",
       "2       0.0        0.0        1.0        0.0\n",
       "3       0.0        0.0        0.0        0.0\n",
       "4       0.0        0.0        0.0        0.0\n",
       "5       0.0        0.0        0.0        0.0\n",
       "6       0.0        0.0        0.0        0.0\n",
       "7       0.0        0.0        0.0        0.0\n",
       "8       0.0        0.0        0.0        0.0\n",
       "9       0.0        0.0        0.0        0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = []\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'5 Epochs': accuracys[0], '10 Epochs': accuracys[1], '20 Epochs': accuracys[2], '50 Epochs': accuracys[3]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:38:57<00:00, 1979.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size: 64</th>\n",
       "      <th>Batch Size: 128</th>\n",
       "      <th>Batch Size: 256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size: 64  Batch Size: 128  Batch Size: 256\n",
       "0             0.0              0.0              0.0\n",
       "1             1.0              0.0              0.0\n",
       "2             0.0              0.0              1.0\n",
       "3             0.0              0.0              0.0\n",
       "4             0.0              1.0              0.0\n",
       "5             0.0              0.0              0.0\n",
       "6             0.0              0.0              0.0\n",
       "7             0.0              0.0              0.0\n",
       "8             0.0              0.0              0.0\n",
       "9             0.0              0.0              0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "        \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size: 64': accuracys[0], 'Batch Size: 128': accuracys[1], 'Batch Size: 256': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [1:57:06<00:00, 2342.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate: 1e-2</th>\n",
       "      <th>Learning Rate: 1e-3</th>\n",
       "      <th>Learning Rate: 1e-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate: 1e-2  Learning Rate: 1e-3  Learning Rate: 1e-4\n",
       "0                  0.0                  0.0                  0.0\n",
       "1                  0.0                  1.0                  0.0\n",
       "2                  0.0                  0.0                  0.0\n",
       "3                  0.0                  0.0                  0.0\n",
       "4                  0.0                  0.0                  0.0\n",
       "5                  1.0                  0.0                  0.0\n",
       "6                  0.0                  0.0                  1.0\n",
       "7                  0.0                  0.0                  0.0\n",
       "8                  0.0                  0.0                  0.0\n",
       "9                  0.0                  0.0                  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=64)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        accuracy, error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate: 1e-2': accuracys[0], 'Learning Rate: 1e-3': accuracys[1], 'Learning Rate: 1e-4': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_C10, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_C10, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train_error = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, test_error = test_for_class(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "        train_loss.append(train_error)\n",
    "        test_loss.append(test_error)\n",
    "\n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    pred_list.append(predicts)\n",
    "    label_list.append(labels)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(test_error)\n",
    "\n",
    "aux_list = []\n",
    "for i in train_loss:\n",
    "    aux_list.append(i.item())\n",
    "\n",
    "df_loss = pd.DataFrame({'Train_loss': aux_list, 'Test_loss': test_loss})\n",
    "df_loss.to_csv('../data/results/cifar10_vgg16_loss.csv', index = False)\n",
    "\n",
    "df_cm = pd.DataFrame({'Pred_1': pred_list[0], 'Label_1':label_list[0], 'Pred_2': pred_list[1], 'Label_2':label_list[1], 'Pred_3': pred_list[2], 'Label_3':label_list[2]})\n",
    "df_cm.to_csv('../data/results/cifar10_vgg16_confusion_matrix.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({'Iter 1': accuracys[0], 'Iter 2': accuracys[1], 'Iter 3': accuracys[2]})\n",
    "df.to_csv('../data/results/cifar10_vgg16_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento e Avaliação - Building-vs-Forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:30<00:00, 97.74s/it] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.692501</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.691036</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.691055</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>52.469813</td>\n",
       "      <td>0.685558</td>\n",
       "      <td>0.524698</td>\n",
       "      <td>0.524698</td>\n",
       "      <td>0.524698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0       5  52.030735  0.692501  0.520307      0.520307   0.520307\n",
       "1      10  52.030735  0.691036  0.520307      0.520307   0.520307\n",
       "2      20  52.030735  0.691055  0.520307      0.520307   0.520307\n",
       "3      50  52.469813  0.685558  0.524698      0.524698   0.524698"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 2)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Epochs': epochs, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [11:08<00:00, 222.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.152476</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.883087</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.775018</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0          64  52.030735  1.152476  0.520307      0.520307   0.520307\n",
       "1         128  52.030735  0.883087  0.520307      0.520307   0.520307\n",
       "2         256  52.030735  0.775018  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))  \n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size': batch_sizes, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [14:21<00:00, 287.29s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.422985</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.188879</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>2.072739</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0         0.0100  52.030735  1.422985  0.520307      0.520307   0.520307\n",
       "1         0.0010  52.030735  1.188879  0.520307      0.520307   0.520307\n",
       "2         0.0001  52.030735  2.072739  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=64)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate': learnings, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_AlexNet(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train_error = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, test_error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "        train_loss.append(train_error)\n",
    "        test_loss.append(test_error)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    pred_list.append(predicts)\n",
    "    label_list.append(labels)\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(test_error)\n",
    "\n",
    "aux_list = []\n",
    "for i in train_loss:\n",
    "    aux_list.append(i.item())\n",
    "\n",
    "df_loss = pd.DataFrame({'Train_loss': aux_list, 'Test_loss': test_loss})\n",
    "df_loss.to_csv('../data/results/bf_alexNet_loss.csv', index = False)\n",
    "\n",
    "df_cm = pd.DataFrame({'Pred_1': pred_list[0], 'Label_1':label_list[0], 'Pred_2': pred_list[1], 'Label_2':label_list[1], 'Pred_3': pred_list[2], 'Label_3':label_list[2]})\n",
    "df_cm.to_csv('../data/results/bf_alexNet_confusion_matrix.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_alexNet_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:58<00:00, 179.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.692524</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.691415</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.690752</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epochs   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0       5  52.030735  0.692524  0.520307      0.520307   0.520307\n",
       "1      10  52.030735  0.692262  0.520307      0.520307   0.520307\n",
       "2      20  52.030735  0.691415  0.520307      0.520307   0.520307\n",
       "3      50  52.030735  0.690752  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = [5, 10, 20, 50]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for epoch in tqdm(epochs):\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 2)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for t in range(epoch):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Epochs': epochs, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_epochs.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Batch Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [27:30<00:00, 550.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.790139</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.074370</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.811420</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0          64  52.030735  0.790139  0.520307      0.520307   0.520307\n",
       "1         128  52.030735  1.074370  0.520307      0.520307   0.520307\n",
       "2         256  52.030735  1.811420  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_sizes = [64, 128, 256]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for batch_size in tqdm(batch_sizes):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "    \n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Batch Size': batch_sizes, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_batchSize.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variando Taxa de Aprendizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [44:42<00:00, 894.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.235880</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>0.787854</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>52.030735</td>\n",
       "      <td>2.105333</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate   Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0         0.0100  52.030735  1.235880  0.520307      0.520307   0.520307\n",
       "1         0.0010  52.030735  0.787854  0.520307      0.520307   0.520307\n",
       "2         0.0001  52.030735  2.105333  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnings = [1e-2, 1e-3, 1e-4]\n",
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "for rate in tqdm(learnings):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=64)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=64)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(error)\n",
    "\n",
    "df = pd.DataFrame({'Learning Rate': learnings, 'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_learnRate.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Avaliando Melhor Configuração:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [41:55<00:00, 838.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Error</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.243675</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.253513</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.030735</td>\n",
       "      <td>1.232855</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "      <td>0.520307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Accuracy     Error  F1 Score  Recall Score  Precision\n",
       "0  52.030735  1.243675  0.520307      0.520307   0.520307\n",
       "1  52.030735  1.253513  0.520307      0.520307   0.520307\n",
       "2  52.030735  1.232855  0.520307      0.520307   0.520307"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracys = []\n",
    "errors = []\n",
    "f1s = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "\n",
    "pred_list = []\n",
    "label_list = []\n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "accuracy = 0\n",
    "error = 999\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "learning = 1e-2\n",
    "\n",
    "for i in tqdm(range(3)):\n",
    "    train_dataloader = DataLoader(training_data_BF, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data_BF, batch_size=batch_size)\n",
    "\n",
    "    model = MY_VGG16(n_classes = 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning)\n",
    "\n",
    "    epochs = 50\n",
    "    for t in range(50):\n",
    "        train_error = train(train_dataloader, model, loss_fn, optimizer, device)\n",
    "        predicts, labels, accuracy, test_error = test_new_metrics(test_dataloader, model, loss_fn, device)\n",
    "\n",
    "        train_loss.append(train_error)\n",
    "        test_loss.append(test_error)\n",
    "    \n",
    "    predicts = np.concatenate(predicts).ravel().tolist()\n",
    "    labels = np.concatenate(labels).ravel().tolist()\n",
    "\n",
    "    pred_list.append(predicts)\n",
    "    label_list.append(labels)\n",
    "\n",
    "    f1s.append(f1_score(labels, predicts, average=\"micro\"))\n",
    "    recalls.append(recall_score(labels, predicts, average=\"micro\"))\n",
    "    precisions.append(precision_score(labels, predicts, average=\"micro\"))\n",
    "    accuracys.append(accuracy)\n",
    "    errors.append(test_error)\n",
    "\n",
    "aux_list = []\n",
    "for i in train_loss:\n",
    "    aux_list.append(i.item())\n",
    "\n",
    "df_loss = pd.DataFrame({'Train_loss': aux_list, 'Test_loss': test_loss})\n",
    "df_loss.to_csv('../data/results/bf_vgg16_loss.csv', index = False)\n",
    "\n",
    "df_cm = pd.DataFrame({'Pred_1': pred_list[0], 'Label_1':label_list[0], 'Pred_2': pred_list[1], 'Label_2':label_list[1], 'Pred_3': pred_list[2], 'Label_3':label_list[2]})\n",
    "df_cm.to_csv('../data/results/bf_vgg16_confusion_matrix.csv', index=False)\n",
    "\n",
    "df = pd.DataFrame({'Accuracy': accuracys, 'Error': errors, 'F1 Score': f1s, 'Recall Score': recalls, 'Precision': precisions})\n",
    "df.to_csv('../data/results/BF_vgg16_bestConfig.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
